{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89e1ad2a-7bf5-43ca-ac78-297366c42b14",
   "metadata": {},
   "source": [
    "### Sentiment Analysis - homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d32e5f3-61f7-44a7-9c21-847baf3b54bb",
   "metadata": {},
   "source": [
    "- https://sites.google.com/view/fiqa/home\n",
    "- https://dl.acm.org/doi/fullHtml/10.1145/3184558.3192301\n",
    "- https://huggingface.co/datasets/pauri32/fiqa-2018?row=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5750eb4-82a1-4b13-880e-044a7e4eed44",
   "metadata": {},
   "source": [
    "The homework is to complete task 1 from the two-tasks challenge from 2018.\n",
    "- Task 1: Aspect-based financial sentiment analysis\n",
    "- Task 2: Opinion-based QA over Financial Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb4876-4772-4306-b94f-0e5b623e681b",
   "metadata": {},
   "source": [
    "Participants should find or create/tune a model to do sentiment analysis of a given phrase.\n",
    "\n",
    "The model can be trained or tuned on dataset \"pauri32/fiqa-2018\" from huggingface.\n",
    "Or participants can use ready \"off-the-shelf\" model.\n",
    "\n",
    "The quality of the results shoudl be evaluated using:\n",
    "- Mean Squared Error (MSE)\n",
    "- R Square (R^2) and Cosine\n",
    "- classification measures: Accuracy, Precision, Recall and F1-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76352fb-addd-474a-9c57-abd0b17968fe",
   "metadata": {},
   "source": [
    "This link provides exampels of input-output tasks: https://sites.google.com/view/fiqa/home"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6270a1d-a553-426f-90b9-4ad7f5c2947e",
   "metadata": {},
   "source": [
    "\"55\": {\n",
    "    \"sentence\": \"Tesco Abandons Video-Streaming Ambitions in Blinkbox Sale\",\n",
    "    \"info\": [\n",
    "\n",
    "      { \"snippets\": \"['Video-Streaming Ambitions']\",\n",
    "        \"target\": \"Blinkbox\",\n",
    "        \"sentiment_score\": \"-0.195\",\n",
    "        \"aspects\": \"['Corporate/Stategy']\"\n",
    "      },\n",
    "\n",
    "      {\n",
    "        \"snippets\": \"['Tesco Abandons Video-Streaming Ambitions ']\",\n",
    "        \"target\": \"Tesco\",\n",
    "        \"sentiment_score\": \"-0.335\",\n",
    "        \"aspects\": \"['Corporate/Stategy']\"\n",
    "      }\n",
    "    ]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3873b5b8-cebd-4fba-a40b-b42a54defeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch pandas numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814085d-62da-47ab-b790-d6c09cdafcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d7919-64a3-4787-a65f-398cc267eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install 'accelerate>={ACCELERATE_MIN_VERSION}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfff2c69-a9a6-4b2f-abf5-5697258970c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading dataset...\n",
      "Training set shape: (961, 2)\n",
      "Test set shape: (150, 2)\n",
      "\n",
      "Loading ProsusAI/finbert model and tokenizer...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80bb45601214c2a8b923eaf45bf1916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/961 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41206b6165a54816a436455398c54b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing trainer...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1574: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [183/183 05:13, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mse</th>\n",
       "      <th>R2</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.258994</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.326311</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.302908</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>-0.986847</td>\n",
       "      <td>0.840091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.443200</td>\n",
       "      <td>1.030048</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.562295</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476822</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>-0.792330</td>\n",
       "      <td>0.816741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.443200</td>\n",
       "      <td>0.911709</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.594359</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566822</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>-0.319933</td>\n",
       "      <td>0.807143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "-------------\n",
      "Accuracy: 0.5667\n",
      "Precision: 0.5944\n",
      "Recall: 0.5667\n",
      "F1 Score: 0.5668\n",
      "MSE: 0.6333\n",
      "RÂ² Score: -0.3199\n",
      "Cosine Similarity: 0.8071\n",
      "\n",
      "Example Predictions:\n",
      "-------------------\n",
      "\n",
      "Text: The company reported strong earnings growth.\n",
      "Predicted sentiment: positive\n",
      "Confidence scores (negative/neutral/positive): ['0.1610', '0.0202', '0.8188']\n",
      "\n",
      "Text: The stock price dropped significantly after the announcement.\n",
      "Predicted sentiment: neutral\n",
      "Confidence scores (negative/neutral/positive): ['0.1858', '0.7376', '0.0766']\n",
      "\n",
      "Text: Investors are cautiously optimistic about the market outlook.\n",
      "Predicted sentiment: positive\n",
      "Confidence scores (negative/neutral/positive): ['0.0891', '0.0630', '0.8479']\n",
      "\n",
      "Model saved to: ./fiqa_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "# Financial Sentiment Analysis using FIQA Dataset\n",
    "# Task 1: Aspect-based Financial Sentiment Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ## 1. Data Loading and Preprocessing\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"pauri32/fiqa-2018\")\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    df['sentence'] = df['sentence'].str.strip()\n",
    "    df['sentiment_score'] = df['sentiment_score'].astype(float)\n",
    "    \n",
    "    df['labels'] = pd.cut(df['sentiment_score'], \n",
    "                         bins=[-float('inf'), -0.3, 0.3, float('inf')], \n",
    "                         labels=[0, 1, 2])\n",
    "    df['labels'] = df['labels'].astype(int)\n",
    "    \n",
    "    return df[['sentence', 'labels']]\n",
    "\n",
    "# Process train and test datasets\n",
    "train_df = preprocess_dataset(dataset['train'])\n",
    "test_df = preprocess_dataset(dataset['test'])\n",
    "\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "# ## 2. Model Setup\n",
    "\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "print(f\"\\nLoading {MODEL_NAME} model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model = model.to(device)  # Move model to appropriate device\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['sentence'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "train_tokenized = train_tokenized.add_column('labels', train_dataset['labels'])\n",
    "test_tokenized = test_tokenized.add_column('labels', test_dataset['labels'])\n",
    "\n",
    "# Set format for pytorch\n",
    "train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ## 3. Model Training\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # Add device specific settings\n",
    "    no_cuda=device == \"cpu\",  # Disable CUDA when not available\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Move tensors to CPU for metric calculation\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.cpu().numpy()\n",
    "    \n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    r2 = r2_score(labels, preds)\n",
    "    cosine_sim = 1 - cosine(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'cosine_similarity': cosine_sim\n",
    "    }\n",
    "\n",
    "print(\"\\nInitializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# ## 4. Evaluation\n",
    "\n",
    "print(\"\\nEvaluating model...\")\n",
    "test_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(\"-------------\")\n",
    "print(f\"Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Precision: {test_results['eval_precision']:.4f}\")\n",
    "print(f\"Recall: {test_results['eval_recall']:.4f}\")\n",
    "print(f\"F1 Score: {test_results['eval_f1']:.4f}\")\n",
    "print(f\"MSE: {test_results['eval_mse']:.4f}\")\n",
    "print(f\"RÂ² Score: {test_results['eval_r2']:.4f}\")\n",
    "print(f\"Cosine Similarity: {test_results['eval_cosine_similarity']:.4f}\")\n",
    "\n",
    "# ## 5. Example Predictions\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    # Move inputs to the same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1)\n",
    "    \n",
    "    # Move results back to CPU for processing\n",
    "    prediction = prediction.cpu()\n",
    "    probabilities = probabilities.cpu()\n",
    "    \n",
    "    sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    predicted_sentiment = sentiment_map[prediction.item()]\n",
    "    \n",
    "    return predicted_sentiment, probabilities[0].tolist()\n",
    "\n",
    "example_sentences = [\n",
    "    \"The company reported strong earnings growth.\",\n",
    "    \"The stock price dropped significantly after the announcement.\",\n",
    "    \"Investors are cautiously optimistic about the market outlook.\"\n",
    "]\n",
    "\n",
    "print(\"\\nExample Predictions:\")\n",
    "print(\"-------------------\")\n",
    "for sentence in example_sentences:\n",
    "    sentiment, probs = predict_sentiment(sentence)\n",
    "    print(f\"\\nText: {sentence}\")\n",
    "    print(f\"Predicted sentiment: {sentiment}\")\n",
    "    print(f\"Confidence scores (negative/neutral/positive): {[f'{p:.4f}' for p in probs]}\")\n",
    "\n",
    "# ## 6. Save Model\n",
    "\n",
    "output_dir = \"./fiqa_sentiment_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"\\nModel saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b8fdc8-2307-4fc2-8f3d-40701653b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample aspects from training data:\n",
      "\n",
      "First 5 aspects:\n",
      "1. ['Stock/Price Action/Volatility/Short Selling']\n",
      "   Type: <class 'str'>\n",
      "2. ['Stock/Price Action/Bearish']\n",
      "   Type: <class 'str'>\n",
      "3. ['Corporate/M&A/M&A']\n",
      "   Type: <class 'str'>\n",
      "4. ['Market/Volatility/Volatility']\n",
      "   Type: <class 'str'>\n",
      "5. ['Stock/Price Action/Bullish/Bullish Behavior']\n",
      "   Type: <class 'str'>\n",
      "\n",
      "Unique aspects (first 10):\n",
      "1. ['Stock/Price Action/Volatility/Short Selling']\n",
      "   Type: <class 'str'>\n",
      "2. ['Stock/Price Action/Bearish']\n",
      "   Type: <class 'str'>\n",
      "3. ['Corporate/M&A/M&A']\n",
      "   Type: <class 'str'>\n",
      "4. ['Market/Volatility/Volatility']\n",
      "   Type: <class 'str'>\n",
      "5. ['Stock/Price Action/Bullish/Bullish Behavior']\n",
      "   Type: <class 'str'>\n",
      "6. ['Corporate/Dividend Policy']\n",
      "   Type: <class 'str'>\n",
      "7. ['Corporate/Sales/Deal']\n",
      "   Type: <class 'str'>\n",
      "8. ['Corporate/Dividend Policy/Dividend']\n",
      "   Type: <class 'str'>\n",
      "9. ['Stock/Price Action/Bearish/Bearish Behavior']\n",
      "   Type: <class 'str'>\n",
      "10. ['Stock/Technical Analysis/MACD']\n",
      "   Type: <class 'str'>\n",
      "\n",
      "Sample complete rows:\n",
      "\n",
      "Row 0:\n",
      "sentence: Still short $LNG from $11.70 area...next stop could be down through $9.00. Someone slammed it hard with 230,000 shs this am! More to follow (Type: <class 'str'>)\n",
      "snippets: ['Still short $LNG from $11.70 area...next stop could be down through $9.00.'] (Type: <class 'str'>)\n",
      "target: LNG (Type: <class 'str'>)\n",
      "sentiment_score: -0.543 (Type: <class 'float'>)\n",
      "aspects: ['Stock/Price Action/Volatility/Short Selling'] (Type: <class 'str'>)\n",
      "format: post (Type: <class 'str'>)\n",
      "label: 2 (Type: <class 'int'>)\n",
      "\n",
      "Row 1:\n",
      "sentence: $PLUG bear raid (Type: <class 'str'>)\n",
      "snippets: ['bear raid'] (Type: <class 'str'>)\n",
      "target: PLUG (Type: <class 'str'>)\n",
      "sentiment_score: -0.48 (Type: <class 'float'>)\n",
      "aspects: ['Stock/Price Action/Bearish'] (Type: <class 'str'>)\n",
      "format: post (Type: <class 'str'>)\n",
      "label: 2 (Type: <class 'int'>)\n",
      "\n",
      "Row 2:\n",
      "sentence: How Kraft-Heinz Merger Came Together in Speedy 10 Weeks (Type: <class 'str'>)\n",
      "snippets: ['Merger Came Together in Speedy 10 Weeks'] (Type: <class 'str'>)\n",
      "target: Kraft (Type: <class 'str'>)\n",
      "sentiment_score: 0.214 (Type: <class 'float'>)\n",
      "aspects: ['Corporate/M&A/M&A'] (Type: <class 'str'>)\n",
      "format: headline (Type: <class 'str'>)\n",
      "label: 0 (Type: <class 'int'>)\n",
      "\n",
      "Row 3:\n",
      "sentence: Slump in Weir leads FTSE down from record high (Type: <class 'str'>)\n",
      "snippets: ['down from record high'] (Type: <class 'str'>)\n",
      "target: Weir (Type: <class 'str'>)\n",
      "sentiment_score: -0.827 (Type: <class 'float'>)\n",
      "aspects: ['Market/Volatility/Volatility'] (Type: <class 'str'>)\n",
      "format: headline (Type: <class 'str'>)\n",
      "label: 2 (Type: <class 'int'>)\n",
      "\n",
      "Row 4:\n",
      "sentence: $AAPL bounces off support, it seems (Type: <class 'str'>)\n",
      "snippets: ['bounces off support'] (Type: <class 'str'>)\n",
      "target: AAPL (Type: <class 'str'>)\n",
      "sentiment_score: 0.443 (Type: <class 'float'>)\n",
      "aspects: ['Stock/Price Action/Bullish/Bullish Behavior'] (Type: <class 'str'>)\n",
      "format: post (Type: <class 'str'>)\n",
      "label: 0 (Type: <class 'int'>)\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the data first\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"pauri32/fiqa-2018\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "# Print some examples of the aspects column\n",
    "print(\"Sample aspects from training data:\")\n",
    "print(\"\\nFirst 5 aspects:\")\n",
    "for i, aspect in enumerate(train_df['aspects'].head(), 1):\n",
    "    print(f\"{i}. {aspect}\")\n",
    "    print(f\"   Type: {type(aspect)}\")\n",
    "\n",
    "# Print unique aspects\n",
    "print(\"\\nUnique aspects (first 10):\")\n",
    "unique_aspects = train_df['aspects'].unique()[:10]\n",
    "for i, aspect in enumerate(unique_aspects, 1):\n",
    "    print(f\"{i}. {aspect}\")\n",
    "    print(f\"   Type: {type(aspect)}\")\n",
    "\n",
    "# Print sample complete rows\n",
    "print(\"\\nSample complete rows:\")\n",
    "for i, row in train_df.head().iterrows():\n",
    "    print(f\"\\nRow {i}:\")\n",
    "    for col in row.index:\n",
    "        print(f\"{col}: {row[col]} (Type: {type(row[col])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "694cd38b-dd3b-402b-9d5a-ff24c0005843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading dataset...\n",
      "\n",
      "Dataset shapes:\n",
      "Training set shape: (961, 7)\n",
      "Test set shape: (150, 7)\n",
      "\n",
      "Aspect Categories Distribution:\n",
      "aspect_category\n",
      "Stock        562\n",
      "Corporate    367\n",
      "Market        28\n",
      "Economy        4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample processed data:\n",
      "                                            sentence                                       aspect aspect_category  sentiment_score\n",
      "0  Still short $LNG from $11.70 area...next stop ...  Stock/Price Action/Volatility/Short Selling           Stock           -0.543\n",
      "1                                    $PLUG bear raid                   Stock/Price Action/Bearish           Stock           -0.480\n",
      "2  How Kraft-Heinz Merger Came Together in Speedy...                            Corporate/M&A/M&A       Corporate            0.214\n",
      "3     Slump in Weir leads FTSE down from record high                 Market/Volatility/Volatility          Market           -0.827\n",
      "4                $AAPL bounces off support, it seems  Stock/Price Action/Bullish/Bullish Behavior           Stock            0.443\n",
      "\n",
      "Loading ProsusAI/finbert model and tokenizer...\n",
      "Tokenizing datasets...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a11fa9c764d41028c4bd180ba679d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/961 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fdc47e459e4b1ab0c0a6f12e924839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing trainer...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/transformers/training_args.py:1574: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='183' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [183/183 04:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Mse</th>\n",
       "      <th>R2</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.817033</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.271958</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.317148</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>-0.980000</td>\n",
       "      <td>0.546829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.882800</td>\n",
       "      <td>1.417513</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.478844</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.852493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.882800</td>\n",
       "      <td>1.471902</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.414260</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.480084</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.802897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Test Results:\n",
      "-------------\n",
      "eval_loss: 1.4175\n",
      "eval_accuracy: 0.5933\n",
      "eval_precision: 0.4049\n",
      "eval_recall: 0.5933\n",
      "eval_f1: 0.4788\n",
      "eval_mse: 0.6267\n",
      "eval_r2: 0.0600\n",
      "eval_cosine_similarity: 0.8525\n",
      "eval_runtime: 3.4021\n",
      "eval_samples_per_second: 44.0900\n",
      "eval_steps_per_second: 2.9390\n",
      "epoch: 3.0000\n",
      "\n",
      "Calculating performance by aspect category...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8abab2d213b4db2aaa7c543cf72bb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5341bea88994690995574e9c0df0b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/levselector/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aspect Category Performance:\n",
      "           accuracy        f1  samples\n",
      "Stock      0.716216  0.631336     74.0\n",
      "Corporate  0.468750  0.334896     64.0\n",
      "\n",
      "Example Predictions:\n",
      "\n",
      "Text: Company reports strong revenue growth but increasing operational costs impact margins\n",
      "\n",
      "Aspect: Corporate/Revenue/Growth\n",
      "Predicted sentiment: negative\n",
      "Confidence scores (negative/neutral/positive): ['0.9491', '0.0127', '0.0382']\n",
      "\n",
      "Aspect: Corporate/Costs/Operating Costs\n",
      "Predicted sentiment: negative\n",
      "Confidence scores (negative/neutral/positive): ['0.6635', '0.0366', '0.2999']\n",
      "\n",
      "Aspect: Corporate/Financial/Margins\n",
      "Predicted sentiment: negative\n",
      "Confidence scores (negative/neutral/positive): ['0.9248', '0.0131', '0.0621']\n",
      "\n",
      "Text: Stock shows high volatility amid market uncertainty and low trading volume\n",
      "\n",
      "Aspect: Stock/Price Action/Volatility\n",
      "Predicted sentiment: positive\n",
      "Confidence scores (negative/neutral/positive): ['0.0838', '0.0325', '0.8837']\n",
      "\n",
      "Aspect: Market/Uncertainty\n",
      "Predicted sentiment: positive\n",
      "Confidence scores (negative/neutral/positive): ['0.0670', '0.0433', '0.8897']\n",
      "\n",
      "Aspect: Stock/Trading Volume\n",
      "Predicted sentiment: positive\n",
      "Confidence scores (negative/neutral/positive): ['0.0851', '0.0381', '0.8768']\n",
      "\n",
      "Model and performance analysis saved to: ./fiqa_aspect_sentiment_model\n"
     ]
    }
   ],
   "source": [
    "# Aspect-based Financial Sentiment Analysis using FIQA Dataset\n",
    "# Task 1: Aspect-based Financial Sentiment Analysis\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, precision_recall_fscore_support\n",
    "from scipy.spatial.distance import cosine\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set up device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ## 1. Data Loading and Preprocessing\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = load_dataset(\"pauri32/fiqa-2018\")\n",
    "\n",
    "def clean_aspect_string(aspect_str):\n",
    "    \"\"\"Clean the aspect string and extract the actual aspect.\"\"\"\n",
    "    # Remove [''] and extract the aspect\n",
    "    aspect = aspect_str.strip(\"[]'\")\n",
    "    return aspect\n",
    "\n",
    "def get_aspect_category(aspect):\n",
    "    \"\"\"Extract main category from aspect.\"\"\"\n",
    "    return aspect.split('/')[0]\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    \n",
    "    # Clean text\n",
    "    df['sentence'] = df['sentence'].str.strip()\n",
    "    \n",
    "    # Clean and extract aspects\n",
    "    df['aspect'] = df['aspects'].apply(clean_aspect_string)\n",
    "    \n",
    "    # Extract aspect categories\n",
    "    df['aspect_category'] = df['aspect'].apply(get_aspect_category)\n",
    "    \n",
    "    # Create combined text with aspect\n",
    "    df['aspect_text'] = '[ASP] ' + df['aspect'] + ' [SEP] ' + df['sentence']\n",
    "    \n",
    "    # Ensure sentiment_score is float\n",
    "    df['sentiment_score'] = df['sentiment_score'].astype(float)\n",
    "    \n",
    "    # Keep relevant columns\n",
    "    return df[['sentence', 'aspect', 'aspect_category', 'aspect_text', 'sentiment_score', 'target', 'label']]\n",
    "\n",
    "# Process datasets\n",
    "train_df = preprocess_dataset(dataset['train'])\n",
    "test_df = preprocess_dataset(dataset['test'])\n",
    "\n",
    "print(\"\\nDataset shapes:\")\n",
    "print(\"Training set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\nAspect Categories Distribution:\")\n",
    "print(train_df['aspect_category'].value_counts())\n",
    "\n",
    "print(\"\\nSample processed data:\")\n",
    "print(train_df[['sentence', 'aspect', 'aspect_category', 'sentiment_score']].head())\n",
    "\n",
    "# ## 2. Model Setup\n",
    "\n",
    "MODEL_NAME = \"ProsusAI/finbert\"\n",
    "print(f\"\\nLoading {MODEL_NAME} model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['aspect_text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "train_tokenized = train_tokenized.add_column('labels', train_dataset['label'])\n",
    "test_tokenized = test_tokenized.add_column('labels', test_dataset['label'])\n",
    "\n",
    "train_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# ## 3. Model Training\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    no_cuda=device == \"cpu\",\n",
    ")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.cpu().numpy()\n",
    "    if isinstance(preds, torch.Tensor):\n",
    "        preds = preds.cpu().numpy()\n",
    "    \n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    mse = mean_squared_error(labels, preds)\n",
    "    r2 = r2_score(labels, preds)\n",
    "    cosine_sim = 1 - cosine(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'mse': mse,\n",
    "        'r2': r2,\n",
    "        'cosine_similarity': cosine_sim\n",
    "    }\n",
    "\n",
    "print(\"\\nInitializing trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# ## 4. Evaluation\n",
    "\n",
    "print(\"\\nEvaluating model...\")\n",
    "test_results = trainer.evaluate()\n",
    "\n",
    "print(\"\\nOverall Test Results:\")\n",
    "print(\"-------------\")\n",
    "for metric, value in test_results.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# ## 5. Aspect-wise Analysis and Examples\n",
    "\n",
    "# Evaluate performance by aspect category\n",
    "def evaluate_by_aspect_category(df, trainer):\n",
    "    results = {}\n",
    "    for category in df['aspect_category'].unique():\n",
    "        category_df = df[df['aspect_category'] == category]\n",
    "        if len(category_df) < 10:  # Skip categories with too few samples\n",
    "            continue\n",
    "            \n",
    "        category_dataset = Dataset.from_pandas(category_df)\n",
    "        category_tokenized = category_dataset.map(\n",
    "            tokenize_function, \n",
    "            batched=True, \n",
    "            remove_columns=category_dataset.column_names\n",
    "        )\n",
    "        category_tokenized = category_tokenized.add_column('labels', category_dataset['label'])\n",
    "        category_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        \n",
    "        category_results = trainer.evaluate(eval_dataset=category_tokenized)\n",
    "        results[category] = {\n",
    "            'accuracy': category_results['eval_accuracy'],\n",
    "            'f1': category_results['eval_f1'],\n",
    "            'samples': len(category_df)\n",
    "        }\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "print(\"\\nCalculating performance by aspect category...\")\n",
    "aspect_performance = evaluate_by_aspect_category(test_df, trainer)\n",
    "print(\"\\nAspect Category Performance:\")\n",
    "print(aspect_performance.sort_values('samples', ascending=False))\n",
    "\n",
    "# Function for aspect-based prediction\n",
    "def predict_aspect_sentiment(text, aspect):\n",
    "    aspect_text = f\"[ASP] {aspect} [SEP] {text}\"\n",
    "    inputs = tokenizer(aspect_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    prediction = torch.argmax(probabilities, dim=-1)\n",
    "    \n",
    "    prediction = prediction.cpu()\n",
    "    probabilities = probabilities.cpu()\n",
    "    \n",
    "    sentiment_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    predicted_sentiment = sentiment_map[prediction.item()]\n",
    "    \n",
    "    return predicted_sentiment, probabilities[0].tolist()\n",
    "\n",
    "# Example predictions\n",
    "print(\"\\nExample Predictions:\")\n",
    "example_texts = [\n",
    "    {\n",
    "        \"text\": \"Company reports strong revenue growth but increasing operational costs impact margins\",\n",
    "        \"aspects\": [\n",
    "            \"Corporate/Revenue/Growth\",\n",
    "            \"Corporate/Costs/Operating Costs\",\n",
    "            \"Corporate/Financial/Margins\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Stock shows high volatility amid market uncertainty and low trading volume\",\n",
    "        \"aspects\": [\n",
    "            \"Stock/Price Action/Volatility\",\n",
    "            \"Market/Uncertainty\",\n",
    "            \"Stock/Trading Volume\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "for example in example_texts:\n",
    "    print(f\"\\nText: {example['text']}\")\n",
    "    for aspect in example['aspects']:\n",
    "        sentiment, probs = predict_aspect_sentiment(example['text'], aspect)\n",
    "        print(f\"\\nAspect: {aspect}\")\n",
    "        print(f\"Predicted sentiment: {sentiment}\")\n",
    "        print(f\"Confidence scores (negative/neutral/positive): {[f'{p:.4f}' for p in probs]}\")\n",
    "\n",
    "# Save model and results\n",
    "output_dir = \"./fiqa_aspect_sentiment_model\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "aspect_performance.to_csv(\"aspect_performance.csv\")\n",
    "\n",
    "print(f\"\\nModel and performance analysis saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32fd09-9465-4f2a-98fc-f78dc6319a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
